{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import time\n",
    "import multiprocessing\n",
    "import copy\n",
    "import os.path as osp\n",
    "# from utils import IdGenerator, id2rgb\n",
    "import pdb\n",
    "import torch\n",
    "try:\n",
    "    import PIL.Image     as Image\n",
    "except:\n",
    "    print(\"Failed to import the image processing packages.\")\n",
    "    sys.exit(-1)\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage='train'  # 'train' or 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_gt_json_file = \"../datasets/lvis/annotations/lvis_v0.5_\"+stage+\".json\"\n",
    "data_path = '../datasets/lvis/images/'+stage+'2017'\n",
    "sorted_cls_id_file = os.path.join('./lvis_sorted_id_all.json')\n",
    "\n",
    "with open(inst_gt_json_file, 'r') as f:\n",
    "    inst_gt = json.load(f)\n",
    "with open(sorted_cls_id_file, 'r') as f:\n",
    "    sorted_cls_id = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set length of the base set & the size of each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_size = 270\n",
    "step_size  = 160\n",
    "n_step = (len(inst_gt['categories']) - base_size) / step_size\n",
    "sorted_class_ids_base = sorted_cls_id[:base_n]\n",
    "json.dump(sorted_class_ids_base, open(os.path.join('../datasets/lvis/annotations', 'lvis_sorted_id_base.json'), 'w'))\n",
    "\n",
    "sorted_class_ids_step = [[] for _ in range(n_step)]\n",
    "for i in range(n_step):\n",
    "    sorted_class_ids_step[i] = sorted_cls_id[:base_n+step_size*(i+1)]\n",
    "    json.dump(sorted_class_ids_step[i], open(os.path.join('../datasets/lvis/annotations', 'lvis_sorted_id_step_'+str(i+1)+'.json'), 'w'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=21.46s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "min_keypoints_per_image = 10\n",
    "\n",
    "\n",
    "def _count_visible_keypoints(anno):\n",
    "    return sum(sum(1 for v in ann[\"keypoints\"][2::3] if v > 0) for ann in anno)\n",
    "\n",
    "\n",
    "def _has_only_empty_bbox(anno):\n",
    "    return all(any(o <= 1 for o in obj[\"bbox\"][2:]) for obj in anno)\n",
    "\n",
    "\n",
    "def has_valid_annotation(anno):\n",
    "    # if it's empty, there is no annotation\n",
    "    if len(anno) == 0:\n",
    "        return False\n",
    "    # if all boxes have close to zero area, there is no annotation\n",
    "    if _has_only_empty_bbox(anno):\n",
    "        return False\n",
    "    # keypoints task have a slight different critera for considering\n",
    "    # if an annotation is valid\n",
    "    if \"keypoints\" not in anno[0]:\n",
    "        return True\n",
    "    # for keypoint detection tasks, only consider valid images those\n",
    "    # containing at least min_keypoints_per_image\n",
    "    if _count_visible_keypoints(anno) >= min_keypoints_per_image:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "class COCODataset(torchvision.datasets.coco.CocoDetection):\n",
    "    def __init__(self, root, ann_file, sorted_id, remove_images_without_annotations=False):\n",
    "        super(COCODataset, self).__init__(root, ann_file)\n",
    "        self.ids = sorted(self.ids)\n",
    "\n",
    "        # filter images without detection annotations\n",
    "        if remove_images_without_annotations:\n",
    "            ids = []\n",
    "            for img_id in self.ids:\n",
    "                ann_ids = self.coco.getAnnIds(imgIds=img_id, catIds = sorted_id,iscrowd=None)\n",
    "#                 ann_ids = self.coco.getAnnIds(imgIds=img_id, iscrowd=None)\n",
    "\n",
    "                anno = self.coco.loadAnns(ann_ids)\n",
    "                if has_valid_annotation(anno):\n",
    "                    ids.append(img_id)\n",
    "            self.ids = ids\n",
    "\n",
    "        self.categories = {cat['id']: cat['name'] for cat in self.coco.cats.values()}\n",
    "\n",
    "        self.category_id_to_sorted_id = {\n",
    "            v: i + 1 for i, v in enumerate(sorted_id)\n",
    "        }\n",
    "        self.sorted_id_to_category_id = {\n",
    "            v: k for k, v in self.category_id_to_sorted_id.items()\n",
    "        }\n",
    "        self.id_to_img_map = {k: v for k, v in enumerate(self.ids)}\n",
    "        self.img_map_to_id = {v: k for k, v in self.id_to_img_map.items()}\n",
    "\n",
    "#         self._transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img, anno = super(COCODataset, self).__getitem__(idx)\n",
    "#         print(anno)\n",
    "        return img, anno, idx\n",
    "    \n",
    "    def get_img_info(self, index):\n",
    "        img_id = self.id_to_img_map[index]\n",
    "        img_data = self.coco.imgs[img_id]\n",
    "        return img_data\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subset construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. base set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_base = COCODataset(data_path, inst_gt_json_file, sorted_class_ids_base, True)\n",
    "\n",
    "inst_gt_subset = inst_gt.copy()\n",
    "annotations_subset = []\n",
    "\n",
    "for class_i in sorted_class_ids_base:\n",
    "    ann_list = dataset_base.coco.getAnnIds(catIds=class_i)\n",
    "    annotations_subset.extend(dataset_base.coco.loadAnns(ids=ann_list))\n",
    "inst_gt_subset['annotations'] = annotations_subset\n",
    "\n",
    "if stage =='val':\n",
    "    for cat_i in inst_gt_subset['categories']:\n",
    "        if cat_i['id'] in sorted_class_ids_base:\n",
    "            cat_i['step_state'] = 'b0'\n",
    "        else:\n",
    "            for step_i in range(n_step):\n",
    "                if cat_i['id'] in sorted_class_ids_step[step_i]:\n",
    "                    cat_i['step_state'] = 't'+str(step_i)\n",
    "json.dump(inst_gt_subset, open(os.path.join('../datasets/lvis/annotations', 'lvis_v0.5_'+stage+'_base.json'), 'w'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. incremental set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if stage == 'train':\n",
    "    for i in range(n_step):\n",
    "        dataset_step_i = COCODataset(data_path, inst_gt_json_file, sorted_class_ids_step[i], True)\n",
    "        inst_gt_step_i = {}\n",
    "        annotations_step_i= []\n",
    "        images_step_i = []\n",
    "        \n",
    "        for class_c in sorted_class_ids_step[i]:\n",
    "            img_ids_cls_c_wo_select = dataset_step_i.coco.getImgIds(catIds=class_c)\n",
    "            img_ids_cls_c = []\n",
    "            for img_id_cls_c in img_ids_cls_c_wo_select:\n",
    "                ann_ids = dataset_step_i.coco.getAnnIds(imgIds=img_id_cls_c, catIds = class_c,iscrowd=None)\n",
    "                anno = dataset_step_i.coco.loadAnns(ann_ids)\n",
    "                if has_valid_annotation(anno):\n",
    "                    img_ids_cls_c.append(img_id_cls_c)\n",
    "            images_step_i.extend(img_ids_cls_c)\n",
    "            annIds = dataset_step_i.coco.getAnnIds(imgIds=img_ids_cls_c, catIds=class_c)\n",
    "            annotations_step_i.extend(dataset_step_i.coco.loadAnns(ids=annIds))\n",
    "        images_step_i = list(np.unique(np.array(images_step_i)))\n",
    "\n",
    "        inst_gt_step_i['annotations'] = annotations_step_i\n",
    "        inst_gt_step_i['categories'] = list(item for item in inst_gt['categories'] if item['id'] in sorted_class_ids_step[i])\n",
    "        inst_gt_step_i['images'] = list(item for item in inst_gt['images'] if item['id'] in images_step_i)\n",
    "\n",
    "        json.dump(inst_gt_step_i, open(os.path.join('../datasets/lvis/annotations', 'lvis_v0.5_train_step'+str(i+1)+'.json'), 'w'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if stage == 'val':\n",
    "    for i in range(n_step):\n",
    "        dataset_step_i = COCODataset(data_path, inst_gt_json_file, sorted_class_ids_step[i], True)\n",
    "        inst_gt_step_i = {}\n",
    "        annotations_step_i= []\n",
    "        images_step_i = []\n",
    "        \n",
    "        for class_c in sorted_class_ids_step[i]:\n",
    "            img_ids_cls_c = dataset_step_i.coco.getImgIds(catIds=class_c)\n",
    "            images_step_i.extend(img_ids_cls_c)\n",
    "            annIds = dataset_step_i.coco.getAnnIds(imgIds=img_ids_cls_c,catIds=class_c)\n",
    "            annotations_step_i.extend(dataset_step_i.coco.loadAnns(ids=annIds))\n",
    "        images_step_i = list(np.unique(np.array(images_step_i)))\n",
    "\n",
    "        inst_gt_step_i['annotations'] = annotations_step_i\n",
    "        inst_gt_step_i['categories'] = list(item for item in inst_gt['categories'] if item['id'] in sorted_class_ids_step[i])\n",
    "        inst_gt_step_i['images'] = list(item for item in inst_gt['images'] if item['id'] in images_step_i)\n",
    "    \n",
    "    for cat_i in inst_gt_step_i['categories']:\n",
    "        if cat_i['id'] in sorted_class_ids_base:\n",
    "            cat_i['step_state'] = 'b0'\n",
    "        else:\n",
    "            for step_i in range(n_step):\n",
    "                if cat_i['id'] in sorted_class_ids_step[step_i]:\n",
    "                    cat_i['step_state'] = 't'+str(step_i)\n",
    "    json.dump(inst_gt_step_i, open(os.path.join('../datasets/lvis/annotations', 'lvis_v0.5_val_step'+str(i+1)+'.json'), 'w'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maskrcnn_benchmark",
   "language": "python",
   "name": "maskrcnn_benchmark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
